from core.rag.prompt_templates import BasePromptTemplate
from langchain.prompts import PromptTemplate


class InferenceTemplate(BasePromptTemplate):
    simple_system_prompt: str = """
    You are an AI language model assistant. Your task is to generate a cohesive and concise response based on the user's question by using a similar writing style and voice.
"""
    simple_prompt_template: str = """
Answer the following question:
{question}
"""

    rag_system_prompt: str = """ You are a specialist in technical content writing. Your task is to create technical content based on a user query given a specific context 
with additional information consisting of the user's previous writings and his knowledge.

Here is a list of steps that you need to follow in order to solve this task:

Step 1: You need to analyze the query between the <query> tags.
Step 2: You need to analyze the provided context and how the information in it relates to the user question between the <context> tags.
Step 3: Generate the content keeping in mind that it needs to be as cohesive and concise as possible based on the query. You will use the users writing style and voice inferred from the question and context.
First try to answer the question based on the context. If the context is irrelevant answer with "I cannot answer your question, as I don't have enough context."
"""
    rag_prompt_template: str = """
Answer the following question:
<question>
{question}
</question>

Given this context:
<context>
{context}
</context>
"""

    def create_template(self, enable_rag: bool = True) -> tuple[str, PromptTemplate]:
        if enable_rag is True:
            return self.rag_system_prompt, PromptTemplate(
                template=self.rag_prompt_template,
                input_variables=["question", "context"],
            )

        return self.simple_system_prompt, PromptTemplate(
            template=self.simple_prompt_template, input_variables=["question"]
        )


class LLMEvaluationTemplate(BasePromptTemplate):
    prompt: str = """
        You are an AI assistant and your task is to evaluate the output generated by another LLM.
        You need to follow these steps:
        Step 1: Analyze the user query: {query}
        Step 2: Analyze the response: {output}
        Step 3: Evaluate the generated response based on the following criteria and provide a score from 1 to 5 along with a brief justification for each criterion:

        Evaluation:
        Relevance - [score]
        [1 sentence justification why relevance = score]
        Coherence - [score]
        [1 sentence justification why coherence = score]
        Conciseness - [score]
        [1 sentence justification why conciseness = score]
"""

    def create_template(self) -> PromptTemplate:
        return PromptTemplate(template=self.prompt, input_variables=["query", "output"])


class RAGEvaluationTemplate(BasePromptTemplate):
    prompt: str = """You are an AI assistant and your task is to evaluate the output generated by another LLM.
    The other LLM generates writing content based on a user query and a given context.
    The given context is comprised of custom data produces by a user that consists of posts, articles or code fragments.
    Here is a list of steps you need to follow in order to solve this task:
    Step 1: You need to analyze the user query : {query}
    Step 2: You need to analyze the given context: {contex}
    Step 3: You need to analyze the generated output: {output}
    Step 4: Generate the evaluation
    When doing the evaluation step you need to take the following into consideration the following:
    -The evaluation needs to have some sort of metrics.
    -The generated content needs to be evaluated based on the writing similarity form the context.
    -The generated content needs to be evaluated based on it's coherence and conciseness related to the given query and context.
    -The generated content needs to be evaluate based on how well it represents the user knowledge extracted from the context."""

    def create_template(self) -> PromptTemplate:
        return PromptTemplate(
            template=self.prompt, input_variables=["query", "context", "output"]
        )
