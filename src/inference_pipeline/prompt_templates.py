from abc import ABC, abstractmethod

import opik
from langchain.prompts import PromptTemplate
from pydantic import BaseModel

from core.rag.prompt_templates import BasePromptTemplate


class LLMEvaluationTemplate(BasePromptTemplate):
    prompt: str = """
        You are an AI assistant and your task is to evaluate the output generated by another LLM.
        You need to follow these steps:
        Step 1: Analyze the user query: {query}
        Step 2: Analyze the response: {output}
        Step 3: Evaluate the generated response based on the following criteria and provide a score from 1 to 5 along with a brief justification for each criterion:

        Evaluation:
        Relevance - [score]
        [1 sentence justification why relevance = score]
        Coherence - [score]
        [1 sentence justification why coherence = score]
        Conciseness - [score]
        [1 sentence justification why conciseness = score]
"""

    def create_template(self) -> PromptTemplate:
        return PromptTemplate(template=self.prompt, input_variables=["query", "output"])


class RAGEvaluationTemplate(BasePromptTemplate):
    prompt: str = """You are an AI assistant and your task is to evaluate the output generated by another LLM.
    The other LLM generates writing content based on a user query and a given context.
    The given context is comprised of custom data produces by a user that consists of posts, articles or code fragments.
    Here is a list of steps you need to follow in order to solve this task:
    Step 1: You need to analyze the user query : {query}
    Step 2: You need to analyze the given context: {contex}
    Step 3: You need to analyze the generated output: {output}
    Step 4: Generate the evaluation
    When doing the evaluation step you need to take the following into consideration the following:
    -The evaluation needs to have some sort of metrics.
    -The generated content needs to be evaluated based on the writing similarity form the context.
    -The generated content needs to be evaluated based on it's coherence and conciseness related to the given query and context.
    -The generated content needs to be evaluate based on how well it represents the user knowledge extracted from the context."""

    def create_template(self) -> PromptTemplate:
        return PromptTemplate(
            template=self.prompt, input_variables=["query", "context", "output"]
        )
